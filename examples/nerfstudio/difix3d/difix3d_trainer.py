# Copyright 2022 The Nerfstudio Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import dataclasses
from dataclasses import dataclass, field
from typing import Type, Literal
from nerfstudio.engine.trainer import Trainer, TrainerConfig
from nerfstudio.engine.callbacks import TrainingCallbackAttributes
from nerfstudio.viewer.viewer import Viewer as ViewerState
from nerfstudio.utils import profiler, writer


@dataclass
class Difix3DTrainerConfig(TrainerConfig):
  """Configuration for the Difix3DTrainer."""

  _target: Type = field(default_factory=lambda: Difix3DTrainer)


class Difix3DTrainer(Trainer):
  """Trainer for Difix3D"""

  def __init__(self, config: TrainerConfig, local_rank: int = 0, world_size: int = 1) -> None:
    super().__init__(config, local_rank, world_size)

  def setup(self, test_mode: Literal["test", "val", "inference"] = "val") -> None:
    """Setup the Trainer by calling other setup functions.

    Args:
        test_mode:
            'val': loads train/val datasets into memory
            'test': loads train/test datasets into memory
            'inference': does not load any dataset into memory
    """
    self.pipeline = self.config.pipeline.setup(
      device=self.device,
      test_mode=test_mode,
      world_size=self.world_size,
      local_rank=self.local_rank,
      grad_scaler=self.grad_scaler,
      render_dir=self.base_dir / "renders",
    )
    self.optimizers = self.setup_optimizers()

    # set up viewer if enabled
    viewer_log_path = self.base_dir / self.config.viewer.relative_log_filename
    self.viewer_state, banner_messages = (None, None)
    if self.config.is_viewer_legacy_enabled() and self.local_rank == 0:
      datapath = self.config.data
      if datapath is None:
        datapath = self.base_dir
      self.viewer_state = ViewerLegacyState(
        self.config.viewer,
        log_filename=viewer_log_path,
        datapath=datapath,
        pipeline=self.pipeline,
        trainer=self,
        train_lock=self.train_lock,
      )
      banner_messages = [f"Legacy viewer at: {self.viewer_state.viewer_url}"]
    if self.config.is_viewer_enabled() and self.local_rank == 0:
      datapath = self.config.data
      if datapath is None:
        datapath = self.base_dir
      self.viewer_state = ViewerState(
        self.config.viewer,
        log_filename=viewer_log_path,
        datapath=datapath,
        pipeline=self.pipeline,
        trainer=self,
        train_lock=self.train_lock,
        share=self.config.viewer.make_share_url,
      )
      banner_messages = self.viewer_state.viewer_info
    self._check_viewer_warnings()

    self._load_checkpoint()

    self.callbacks = self.pipeline.get_training_callbacks(
      TrainingCallbackAttributes(
        optimizers=self.optimizers,
        grad_scaler=self.grad_scaler,
        pipeline=self.pipeline,
        trainer=self,
      )
    )

    # set up writers/profilers if enabled
    writer_log_path = self.base_dir / self.config.logging.relative_log_dir
    writer.setup_event_writer(
      self.config.is_wandb_enabled(),
      self.config.is_tensorboard_enabled(),
      self.config.is_comet_enabled(),
      log_dir=writer_log_path,
      experiment_name=self.config.experiment_name,
      project_name=self.config.project_name,
    )
    writer.setup_local_writer(
      self.config.logging, max_iter=self.config.max_num_iterations, banner_messages=banner_messages
    )
    writer.put_config(name="config", config_dict=dataclasses.asdict(self.config), step=0)
    profiler.setup_profiler(self.config.logging, writer_log_path)
